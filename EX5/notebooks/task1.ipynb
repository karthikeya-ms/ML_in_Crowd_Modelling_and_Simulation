{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ac2d9a2816c7f5",
   "metadata": {},
   "source": [
    "# Example Notebook\n",
    "\n",
    "This notebook serves to show how to create a notebook in the current directory structure.\n",
    "\n",
    "Simply, after importing `init_notebook` the user can both import the `test_module` and its `test_function`, located in the `src` directory. Finally, it also becomes possible to open files in the `data` folder directly. All paths are relative to this directory so it is also possible to directly save a file to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418505379a50fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# matplotlib pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import init_notebook\n",
    "import task1_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906d50ca11631fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global linear_data, nonlinear_data\n",
    "linear_data = np.loadtxt(\"task_1/linear_function_data.txt\", delimiter=\" \")\n",
    "nonlinear_data = np.loadtxt(\"task_1/nonlinear_function_data.txt\", delimiter=\" \")\n",
    "assert linear_data.shape == (1000, 2) and nonlinear_data.shape == (1000, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799572b07137fd48",
   "metadata": {},
   "source": [
    "# Visualize data\n",
    "\n",
    "We want to create an approximation function $\\hat{f}: \\mathbb{R} \\to \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330994e95c49adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(linear_data[:, 0], linear_data[:, 1])\n",
    "plt.scatter(nonlinear_data[:, 0], nonlinear_data[:, 1])\n",
    "plt.legend([\"linear\", \"nonlinear\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06ba7a33c6bfd5",
   "metadata": {},
   "source": [
    "# Solving linear data\n",
    "\n",
    "Since we ignore linear-affine cases, The linear data is created by a function $$f: \\mathbb{R} \\to \\mathbb{R}$$ $$x \\mapsto \\alpha x$$\n",
    "\n",
    "We use **least square minimization** to find the best approximation function $\\hat{f}$, $\\hat{f}(x) = \\beta x$ given our data, where our error is given by the squares of the differences between $\\hat{f}$ and $f$.\n",
    "\n",
    "We can formulate our problem as a vectorized linear equation:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2  \\\\\n",
    "\\vdots \\\\\n",
    "x_{1000}\n",
    "\\end{bmatrix}\n",
    "\\beta =\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_{1000}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The error function is given by the squared mean of the residuals:\n",
    "\n",
    "$$\\min_{\\hat{f}}e(\\hat{f}) \\propto \\min_{\\beta} \\sum_{i=1}^{1000} (\\beta x_i - y_i)^2$$\n",
    "\n",
    "The solution for $\\beta$ given by the least square minimization minimizes our error function. In the `numpy.linalg.lstsq` function, the solution $\\beta$ is given by a 1x1 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba6a7063bf8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_linear, residuals = utils.linear_approximate_1d(linear_data[:, 0], linear_data[:, 1])\n",
    "solution_closed_form = utils.linear_approximate_closed_form(linear_data[:, 0], linear_data[:, 1])\n",
    "assert np.allclose(solution_linear, solution_closed_form)\n",
    "\n",
    "print(f'Solution: {solution_linear}, residual: {residuals}')\n",
    "\n",
    "\n",
    "# also plot nonlinear fit to linear data\n",
    "l_vector = np.linspace(np.min(linear_data[:, 0]), np.max(linear_data[:,0]), 10)\n",
    "utils.rbf_interpolate(linear_data[:, 0], linear_data[:, 1], 0.75, l_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1639207a98f77",
   "metadata": {},
   "source": [
    "# Approximate nonlinear data with a linear function\n",
    "\n",
    "Same procedure as above but the results are poor:\n",
    "\n",
    "Solution: 0.03321036, residual: 774.8919879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e86111f7206bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_linear, residuals = utils.linear_approximate_1d(nonlinear_data[:, 0], nonlinear_data[:, 1])\n",
    "solution_closed_form = utils.linear_approximate_closed_form(nonlinear_data[:, 0], nonlinear_data[:, 1])\n",
    "assert np.allclose(solution_linear, solution_closed_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53fc6d702579be",
   "metadata": {},
   "source": [
    "# Approximate nonlinear data with radial basis functions\n",
    "\n",
    "We notice that the data is not linear, but rather a sinusoidal function. We can approximate this function with a linear combination of radial basis functions. We count the peaks and troughs of the data and use this as the number of radial basis functions. This is because our basis of nonlinear functions is given by the following:\n",
    "\n",
    "$$\\phi_l(x) = \\exp\\left(-\\left(\\frac{x-x_l}{\\epsilon^2}\\right)^2\\,\\,\\right)$$\n",
    "\n",
    "This denotes a sharp peak around $x_l$. In order to mimic our data, we use a linear combination of $\\phi_l$ functions.\n",
    "\n",
    "Our apoproximation function is given by a linear combination of these functions: $$\\hat{f}(x) = \\sum_{l=1}^L c_l\\, \\phi_l(x)$$\n",
    "\n",
    "The only unknowns are the coefficients $c_l$ and the width $\\epsilon$ of the peaks. We can formulate our problem as a linear equation:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "\\phi_1(x_1) & \\phi_2(x_1) & \\cdots & \\phi_L(x_1) \\\\\n",
    "\\phi_1(x_2) & \\phi_2(x_2) & \\cdots & \\phi_L(x_2) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\phi_1(x_{1000}) & \\phi_2(x_{1000}) & \\cdots & \\phi_L(x_{1000})\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "c_1 \\\\\n",
    "c_2 \\\\\n",
    "\\vdots \\\\\n",
    "c_L\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_{1000}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "We use least square minimization to find the best coefficients $c_l$.\n",
    "\n",
    "We need $L \\ge 6$, otherwise we cannot have enough peaks and troughs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6dad3de613106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x = nonlinear_data[np.argmax(nonlinear_data[:, 1]), 0]\n",
    "max_y = nonlinear_data[np.argmax(nonlinear_data[:, 1]), 1]\n",
    "\n",
    "\n",
    "plt.scatter(nonlinear_data[:, 0], nonlinear_data[:, 1])\n",
    "x = np.linspace(max_x-1, max_x+1, 1000)\n",
    "# Test different values of epsilon to see what shape fits best. Focus on the shape around the peak.\n",
    "for epsilon in [0.3, 0.5, 0.6]:\n",
    "  # scale by max_y to fit the peak itself\n",
    "  y = max_y * np.exp(-((x-max_x)/epsilon)**2)\n",
    "  plt.plot(x, y, color = \"red\", linewidth=1)\n",
    "plt.title(f'Radial axis around peak with different values of epsilon')\n",
    "# restrict x axis to -1 and 2\n",
    "plt.xlim(-1, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272397ad8cb4769",
   "metadata": {},
   "source": [
    "# 1. Even spacing of $x_l$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520a1d2e04a1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change epsilon to your liking here\n",
    "epsilon = 2\n",
    "min = np.min(nonlinear_data[:, 0])\n",
    "max = np.max(nonlinear_data[:, 0])\n",
    "\n",
    "l_vector = np.linspace(min, max, 8)\n",
    "utils.rbf_interpolate(nonlinear_data[:, 0], nonlinear_data[:, 1], 2, l_vector)\n",
    "\n",
    "l_vector = np.linspace(min, max, 10)\n",
    "utils.rbf_interpolate(nonlinear_data[:, 0], nonlinear_data[:, 1], 2, l_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24cd86763d91d9",
   "metadata": {},
   "source": [
    "# Cherrypicked $x_l$ values\n",
    "\n",
    "This has delivered the best results. Unfortunately, this is not a general solution and is difficult to automate, especially for more complex or higher-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b733ee3a86744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cherrypicked vector\n",
    "l_vector = np.array([ -2.4, -1.35, -0.70, 0.4, 1.6, 2.7])\n",
    "\n",
    "utils.rbf_interpolate(nonlinear_data[:, 0], nonlinear_data[:, 1], 0.7, l_vector)\n",
    "\n",
    "l_vector = np.array([min, -2.4, -1.35, -0.70, 0.4, 1.6, 2.7, max])\n",
    "utils.rbf_interpolate(nonlinear_data[:, 0], nonlinear_data[:, 1], 0.7, l_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9881a0cc75ec0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_vector = utils.get_extrema(nonlinear_data[:, 0], nonlinear_data[:, 1], 15)\n",
    "utils.rbf_interpolate(nonlinear_data[:, 0], nonlinear_data[:, 1], epsilon, l_vector)\n",
    "\n",
    "l_vector = utils.get_extrema(nonlinear_data[:, 0], nonlinear_data[:, 1], 10)\n",
    "utils.rbf_interpolate(nonlinear_data[:, 0], nonlinear_data[:, 1], epsilon, l_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
