{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_notebook\n",
    "\n",
    "from math import pi as PI\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "from src.models.gaussian_process.regression import GaussianProcessRegressor\n",
    "from src.models.gaussian_process.binary_classification import GaussianProcessClassifier\n",
    "from src.models.gaussian_process.kernels import RadialBasisFunction, Periodic, ComposeMultiply\n",
    "\n",
    "from src.data.data_helpers import load_diabetes_sklearn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gp_rbf(X, y, variance=1, length_scale=1, noise_variacne=0):\n",
    "    # variance controls the variance of the prior\n",
    "    # length controls speed to \"come back\" to prior\n",
    "    rbf = RadialBasisFunction(variance=variance, length=length_scale)\n",
    "\n",
    "    # noise_variance controls how tightly the GP sticks to the training data\n",
    "    gp = GaussianProcessRegressor(rbf, noise_variance=noise_variacne)\n",
    "    gp.train(X, y)\n",
    "\n",
    "    return gp\n",
    "\n",
    "def train_gp_periodic(X, y, variance=1, length_scale=1, period=1, noise_variacne=0):\n",
    "    # variance controls the variance of the prior\n",
    "    # length controls speed to \"come back\" to prior\n",
    "    p_kernel = Periodic(variance=variance, length=length_scale, period=period)\n",
    "\n",
    "    # noise_variance controls how tightly the GP sticks to the training data\n",
    "    gp = GaussianProcessRegressor(p_kernel, noise_variance=noise_variacne)\n",
    "    gp.train(X, y)\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit_example_1(X, y, *, variance=1, length_scale=1, noise_variacne=1, save_name=None):\n",
    "    # Train GP\n",
    "    rbf = RadialBasisFunction(variance=variance, length=length_scale)\n",
    "    gp = GaussianProcessRegressor(rbf, noise_variance=noise_variacne)\n",
    "    gp.train(X, y)\n",
    "\n",
    "    # Get plot data\n",
    "    X_test = np.linspace(0, 20, num=100).reshape(-1, 1)\n",
    "    predictions, covariances  = gp.get_distribution(X_test)\n",
    "\n",
    "    # Make prediction figure and plot\n",
    "    prediction_fig = plt.figure()\n",
    "    pred_graph = prediction_fig.add_subplot(111)\n",
    "    pred_graph.set_xlabel('x')\n",
    "    pred_graph.set_ylabel('y')\n",
    "    \n",
    "    # Plot fitted function and variances\n",
    "    pred_graph.plot(X_test, predictions, color='#ED5050')\n",
    "    pred_graph.plot(X_test, predictions+(covariances), color='#E3CFCF')\n",
    "    pred_graph.plot(X_test, predictions-(covariances), color='#E3CFCF')\n",
    "\n",
    "    # Scatter data points\n",
    "    pred_graph.scatter(X, y, marker='x')\n",
    "\n",
    "    # Save figure\n",
    "    if save_name is not None:\n",
    "        prediction_fig.savefig(f'task_1/{save_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0.1],\n",
    "    [2],\n",
    "    [2.1],\n",
    "    [5],\n",
    "    [9],\n",
    "    [12]\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    [1.8],\n",
    "    [2],\n",
    "    [2.2],\n",
    "    [1],\n",
    "    [3],\n",
    "    [3.4]\n",
    "])\n",
    "\n",
    "# (variance, length_scale, noise_variance, save_bool)\n",
    "configs = [\n",
    "    (1, 1, 0   , True),\n",
    "    (2, 1, 0   , True),\n",
    "    (1, 2, 0   , True),\n",
    "    (1, 1, 0.007, True)\n",
    "]\n",
    "\n",
    "for v, l, n, s in configs:\n",
    "    if s:\n",
    "        plot_fit_example_1(X,y, \n",
    "            variance=v, \n",
    "            length_scale=l,\n",
    "            noise_variacne=n,\n",
    "            save_name=f'v={v}-l={l}-n={n}'\n",
    "        )\n",
    "    else:\n",
    "        plot_fit_example_1(X,y, \n",
    "            variance=v,\n",
    "            length_scale=l,\n",
    "            noise_variacne=n\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_helpers import forrester_function, load_forrester\n",
    "\n",
    "X = np.linspace(-5, 5, num=200)\n",
    "y = forrester_function(X)\n",
    "\n",
    "forrester_fig = plt.figure()\n",
    "\n",
    "forrester_plot = forrester_fig.add_subplot(111)\n",
    "\n",
    "forrester_plot.plot(X, y, color='#ED5050')\n",
    "\n",
    "forrester_fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_forrester(\n",
    "    begin=-2.5, end=2.5, noise_variance=0, n_samples=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = train_gp_rbf(X_train, y_train, variance=50, length_scale=5, noise_variacne=0)\n",
    "\n",
    "X_plot = np.linspace(-5, 5, num=250).reshape(-1,1)\n",
    "predictions, covariances  = gp.get_distribution(X_plot)\n",
    "\n",
    "prediction_fig = plt.figure()\n",
    "pred_graph = prediction_fig.add_subplot(111)\n",
    "\n",
    "pred_graph.plot(X_plot, predictions+covariances, color='#E3CFCF')\n",
    "pred_graph.plot(X_plot, predictions-covariances, color='#E3CFCF')\n",
    "pred_graph.plot(X_plot, predictions)\n",
    "\n",
    "pred_graph.scatter(X_train, y_train, marker='.', color='green')\n",
    "pred_graph.scatter(X_test, y_test, marker='x', color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = train_gp_periodic(X_train, y_train, variance=1, length_scale=1, period=2.5, noise_variacne=0)\n",
    "\n",
    "X_plot = np.linspace(-5, 5, num=250).reshape(-1,1)\n",
    "predictions, covariances  = gp.get_distribution(X_plot)\n",
    "\n",
    "prediction_fig = plt.figure()\n",
    "pred_graph = prediction_fig.add_subplot(111)\n",
    "\n",
    "pred_graph.plot(X_plot, predictions+covariances, color='#E3CFCF')\n",
    "pred_graph.plot(X_plot, predictions-covariances, color='#E3CFCF')\n",
    "pred_graph.plot(X_plot, predictions)\n",
    "\n",
    "pred_graph.scatter(X_train, y_train, marker='.', color='green')\n",
    "pred_graph.scatter(X_test, y_test, marker='x', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Periodic(variance=1, length=3, period=1)\n",
    "rbf = RadialBasisFunction(variance=1, length=1)\n",
    "kernel = ComposeMultiply([rbf, p])\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel, noise_variance=0)\n",
    "gp.train(X_train, y_train)\n",
    "\n",
    "X_plot = np.linspace(-5, 5, num=250).reshape(-1,1)\n",
    "predictions, covariances  = gp.get_distribution(X_plot)\n",
    "\n",
    "prediction_fig = plt.figure()\n",
    "pred_graph = prediction_fig.add_subplot(111)\n",
    "\n",
    "pred_graph.plot(X_plot, predictions+covariances, color='#E3CFCF')\n",
    "pred_graph.plot(X_plot, predictions-covariances, color='#E3CFCF')\n",
    "pred_graph.plot(X_plot, predictions)\n",
    "\n",
    "pred_graph.scatter(X_train, y_train, marker='.', color='green')\n",
    "pred_graph.scatter(X_test, y_test, marker='x', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_diabetes_sklearn(validation_size=0.1)\n",
    "pca = PCA(4)\n",
    "scaler = StandardScaler()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = pca.transform(X_test)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = -np.inf\n",
    "best_config = {'v':0,'l':0,'n':0}\n",
    "for v in np.linspace(7.3, 50, num=1):\n",
    "    for l in np.linspace(0.8, 100, num=1):\n",
    "        for n in np.linspace(2.17, 3, num=1):\n",
    "            rbf = RadialBasisFunction(variance=v, length=l)\n",
    "\n",
    "            gp = GaussianProcessRegressor(kernel=rbf, noise_variance=n)\n",
    "            gp.train(X_train, y_train)\n",
    "\n",
    "            current = gp.log_marginal_likelihood\n",
    "            if current != np.inf and current > best:\n",
    "                best = current\n",
    "                best_config['v'] = v\n",
    "                best_config['l'] = l\n",
    "                best_config['n'] = n\n",
    "                with open('tunning.txt', 'a') as file:\n",
    "                    file.write(f'Likelihood: {current}\\nConfig: {best_config}\\n\\n')\n",
    "\n",
    "predictions, covariances = gp.get_distribution(X_test)\n",
    "p_values = []\n",
    "for pred, cov, target in zip(predictions, covariances, y_test):\n",
    "    pred = pred[0]\n",
    "    cov = cov[0]\n",
    "    p_values.append(2 * (1 - norm.cdf(abs((target - pred) / cov))))\n",
    "\n",
    "print(sum(errors)/len(errors))\n",
    "\n",
    "ep_fig = plt.figure(figsize=(10,5))\n",
    "ec_plot = ep_fig.add_subplot(111)\n",
    "#ep_plot = ep_fig.add_subplot(212)\n",
    "\n",
    "# ep_plot.scatter(abs(predictions.reshape(-1) - y_test), p_values, marker='.')\n",
    "# ep_plot.set_xlabel('Absolute Error')\n",
    "# ep_plot.set_ylabel('p-value')\n",
    "\n",
    "ec_plot.scatter(abs(predictions.reshape(-1) - y_test), covariances, marker='.')\n",
    "ec_plot.set_xlabel('Absolute Error')\n",
    "ec_plot.set_ylabel('Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
