{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Training a Variational Autoencoder on MNIST\n",
    "\n",
    "in this task, we will train a variational autoencoder to reconstruct and generate images of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_notebook\n",
    "import warnings\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from vae import VAETrainer, VAEConfig\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to download tthe dsta. We are using pytorch's own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist =  MNIST(root = './', download = True)\n",
    "X = mnist.data\n",
    "y = mnist.targets\n",
    "\n",
    "print(f\"input shape:\",list(X.shape))\n",
    "print(f\"targets/y shape:\",list(y.shape))\n",
    "print(\"pixel [min, max]:\",f\"[{X.min().item()}, {X.max().item()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot a random sample of 3 images from the dataset to see what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_random_indices = np.random.randint(low=0, high=X.shape[0] - 1, size=3)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 5))\n",
    "\n",
    "for i, axis in zip(three_random_indices, axes):\n",
    "    image = X[i]\n",
    "    axis.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do simple preprocessing steps in order to prepare the data for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255\n",
    "print(X.min().item(), X.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.view(X.shape[0], -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "\n",
    "randomindices = torch.randperm(n)\n",
    "train_size = int(0.8 * n)\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test = X[train_size:]\n",
    "y_test = y[train_size:]\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "print(\"Train-Test Split:\", train_size, n - train_size)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Training\n",
    "We now train the dataset using the different scenarios in the exercise sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration I: 2 Latent Dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VAEConfig(\n",
    "    input_dim=28 * 28,\n",
    "    latent_dim=2,\n",
    "    encoder_layers=[256, 256],\n",
    "    decoder_layers=[256, 256],\n",
    "    learning_rate=0.001,\n",
    "    batch_size=128,\n",
    "    epochs=200,\n",
    "    visualization_interval=[1, 5, 25, 50],\n",
    "    output_linear=False\n",
    ")\n",
    "\n",
    "vae_trainer = VAETrainer(config=config, train_set=train_dataset, test_set=test_dataset)\n",
    "vae_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration II: 32 Latent Dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VAEConfig(\n",
    "    input_dim=28 * 28,\n",
    "    latent_dim=32,\n",
    "    encoder_layers=[256, 256],\n",
    "    decoder_layers=[256, 256],\n",
    "    learning_rate=0.001,\n",
    "    batch_size=128,\n",
    "    epochs=200,\n",
    "    visualization_interval=[1, 5, 25, 50],\n",
    ")\n",
    "\n",
    "vae_trainer = VAETrainer(config=config, train_set=train_dataset, test_set=test_dataset)\n",
    "vae_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCMS_GroupI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
