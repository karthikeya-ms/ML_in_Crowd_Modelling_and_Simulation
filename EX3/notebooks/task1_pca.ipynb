{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Principal Component Analysis\n",
    "\n",
    "This notebook is a showcase of our `pca` module, which implements Principal Component Analysis (PCA).\n",
    "\n",
    "PCA is a method for dimensionality reduction, performing well on affine-linear data.\n",
    "\n",
    "First, the data is centered by subtracting the average datapoint from each datapoint. Then, we perform singular value decomposition on the centered data.\n",
    "\n",
    "The trick is to reverse the singular value decomposition by setting the least important singular values to 0, and then multiplying the matrices back together. This is possible because the singular values are ordered by magnitude, and the least important singular values are the ones that contribute the least to the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_notebook\n",
    "from test_module import test_function\n",
    "from pca import PCA\n",
    "\n",
    "# Helper module for visualization in this notebook\n",
    "from pca_utils import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "test_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "We load the data from a file and perform PCA.\n",
    "\n",
    "It's apparent that one of the principal components accounts for over 99.3% of the variance in the data, which motivates us to the assumption that the other principal component is just noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pca_dataset.txt\", 'r') as file:\n",
    "    # Load data inta a Python ndarray, shape (100, 2)\n",
    "    global data_matrix\n",
    "    data_matrix = np.loadtxt(file, delimiter=' ')\n",
    "    assert data_matrix.shape == (100, 2)\n",
    "\n",
    "pca_result = PCA.pca(data_matrix)\n",
    "\n",
    "# This is how we can access the data of our PCA result\n",
    "U, S, Vh, mean = pca_result\n",
    "E = pca_result.energy\n",
    "\n",
    "print(f'Energies: {E}\\nSingular values ordered by magnitude: {S}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reversing PSA to verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix_reconstructed = pca_result.reverse_pca(2)\n",
    "\n",
    "# Before and after display side-by-side\n",
    "display_side_by_side = False\n",
    "if display_side_by_side:\n",
    "    for o, r in zip(data_matrix, data_matrix_reconstructed):\n",
    "        print(f'o: {o}, r: {r}')\n",
    "\n",
    "assert np.allclose(data_matrix, data_matrix_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting data\n",
    "\n",
    "The plot looks suspiciously linear, which further supports the assumption that a linear model is very suitable for this dataset. The green principal component seems to be just noise, with no discernable patterns. The points align strongly with the red principal component.\n",
    "\n",
    "PSA is a great approach for data that shows affine-linear behavior, as opposed to data on curved manifolds. This is why it makes sense to use PSA for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_with_pcs(data_matrix, Vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate 1D\n",
    "\n",
    "Eliminating the lesser principal component and approximating the data with only the first principal component, the data is approximated to a 1D line. This is done by simply setting the second singular value to 0 inside the matrix of singular values given by `S`, and then reversing the PCA by multiplying the matrices `U`, `S`, and `Vh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply 1 to reverse_pca to approximate the data to 1D\n",
    "approximated_data = pca_result.reverse_pca(1)\n",
    "\n",
    "plot_data_with_pcs(approximated_data, pca_result.Vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image\n",
    "\n",
    "We load the racoon image in gray and perform PCA on it.\n",
    "\n",
    "**Note:** `scipy.misc.face` from the exercise sheet is deprecated because `scipy.misc` is deprecated. We use `scipy.datasets.face` instead.\n",
    "\n",
    "Scaling the image to 249x185 pixels, we know that the image has **185 principal components.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image as `ndarray`\n",
    "my_image = sc.datasets.face(gray=True)\n",
    "my_image = rescale_img(my_image, 249, 185)\n",
    "\n",
    "plt.imshow(my_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on image\n",
    "We perform PCA on the image, and print some of the singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the columns as datapoints, hence specify the flag. This 'flattens' the image\n",
    "# The flag also ensures that the reconstructed image is transposed back to the original shape\n",
    "pca_result_img = PCA.pca(my_image, treat_columns_as_datapoints=True)\n",
    "\n",
    "print_pca_info(pca_result_img, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of reconstructions\n",
    "\n",
    "We visualize for different numbers of components.\n",
    "\n",
    "Slight quality detriments are noticeable starting from 50 components, especially around the racoon's fur.\n",
    "\n",
    "The image with 10 components is barely recogniziable despite preserving over 83% of the energy. The racoon's face is still possible to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstructions with different numbers of principal components\n",
    "for num_components in [pca_result_img.S.shape[0], 120, 50, 10]:\n",
    "    plot_reconstructed_image(pca_result_img, num_components, my_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of components for less than 1% energy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of components needed to retain a percentage of the energy\n",
    "energy_threshold = 0.99\n",
    "n = pca_result_img.S.shape[0]\n",
    "while np.sum(pca_result_img.energy[:n-1]) > energy_threshold:\n",
    "    n -= 1\n",
    "\n",
    "print(f'Number of components needed to retain 99% of the energy: {n}')\n",
    "print(f'We can remove {pca_result_img.S.shape[0] - n} dimensions from our image\\'s columns while retaining {energy_threshold*100}% of the information')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCMS_GroupI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
