{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Principal Component Analysis\n",
    "\n",
    "This notebook is a showcase of our `pca` module, which implements Principal Component Analysis (PCA).\n",
    "\n",
    "PCA is a method for dimensionality reduction, performing well on affine-linear data.\n",
    "\n",
    "First, the data is centered by subtracting the average datapoint from each datapoint. Then, we perform singular value decomposition on the centered data.\n",
    "\n",
    "The trick is to reverse the singular value decomposition by setting the least important singular values to 0, and then multiplying the matrices back together. This is possible because the singular values are ordered by magnitude, and the least important singular values are the ones that contribute the least to the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_notebook\n",
    "from test_module import test_function\n",
    "from pca import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper module for visualization in this notebook\n",
    "from pca_utils import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "test_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "We load the data from a file and perform PCA.\n",
    "\n",
    "It's apparent that one of the principal components accounts for over 99.3% of the variance in the data, which motivates us to the assumption that the other principal component is just noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pca_dataset.txt\", 'r') as file:\n",
    "    # Load data inta a Python ndarray, shape (100, 2)\n",
    "    global data_matrix\n",
    "    data_matrix = np.loadtxt(file, delimiter=' ')\n",
    "    assert data_matrix.shape == (100, 2)\n",
    "\n",
    "pca_result = PCA.pca(data_matrix)\n",
    "\n",
    "# This is how we can access the data of our PCA result\n",
    "U, S, Vh, mean = pca_result\n",
    "E = pca_result.energy\n",
    "\n",
    "print(f'Energies: {E}\\nSingular values ordered by magnitude: {S}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reversing PSA to verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix_reconstructed = pca_result.reverse_pca(2)\n",
    "\n",
    "# Before and after display side-by-side\n",
    "display_side_by_side = False\n",
    "if display_side_by_side:\n",
    "    for o, r in zip(data_matrix, data_matrix_reconstructed):\n",
    "        print(f'o: {o}, r: {r}')\n",
    "\n",
    "assert np.allclose(data_matrix, data_matrix_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting data\n",
    "\n",
    "The plot looks suspiciously linear, which further supports the assumption that a linear model is very suitable for this dataset. The green principal component seems to be just noise, with no discernable patterns. The points align strongly with the red principal component.\n",
    "\n",
    "PSA is a great approach for data that shows affine-linear behavior, as opposed to data on curved manifolds. This is why it makes sense to use PSA for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_with_pcs(data_matrix, Vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate 1D\n",
    "\n",
    "Eliminating the lesser principal component and approximating the data with only the first principal component, the data is approximated to a 1D line. This is done by simply setting the second singular value to 0 inside the matrix of singular values given by `S`, and then reversing the PCA by multiplying the matrices `U`, `S`, and `Vh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply 1 to reverse_pca to approximate the data to 1D\n",
    "approximated_data = pca_result.reverse_pca(1)\n",
    "\n",
    "plot_data_with_pcs(approximated_data, pca_result.Vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image\n",
    "\n",
    "We load the racoon image in gray and perform PCA on it.\n",
    "\n",
    "**Note:** `scipy.misc.face` from the exercise sheet is deprecated because `scipy.misc` is deprecated. We use `scipy.datasets.face` instead.\n",
    "\n",
    "Scaling the image to 249x185 pixels, we know that the image has **185 principal components.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image as `ndarray`\n",
    "my_image = sc.datasets.face(gray=True)\n",
    "my_image = rescale_img(my_image, 249, 185)\n",
    "\n",
    "plt.imshow(my_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on image\n",
    "We perform PCA on the image, and print some of the singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the columns as datapoints, hence specify the flag. This 'flattens' the image\n",
    "# The flag also ensures that the reconstructed image is transposed back to the original shape\n",
    "pca_result_img = PCA.pca(my_image, treat_columns_as_datapoints=True)\n",
    "\n",
    "print_pca_info(pca_result_img, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of reconstructions\n",
    "\n",
    "We visualize for different numbers of components.\n",
    "\n",
    "Slight quality detriments are noticeable starting from 50 components, especially around the racoon's fur.\n",
    "\n",
    "The image with 10 components is barely recogniziable despite preserving over 83% of the energy. The racoon's face is still possible to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstructions with different numbers of principal components\n",
    "for num_components in [pca_result_img.S.shape[0], 120, 50, 10]:\n",
    "    plot_reconstructed_image(pca_result_img, num_components, my_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of components for less than 1% energy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of components needed to retain a percentage of the energy\n",
    "energy_threshold = 0.99\n",
    "n = pca_result_img.S.shape[0]\n",
    "while np.sum(pca_result_img.energy[:n-1]) > energy_threshold:\n",
    "    n -= 1\n",
    "\n",
    "print(f'Number of components needed to retain 99% of the energy: {n}')\n",
    "print(f'We can remove {pca_result_img.S.shape[0] - n} dimensions from our image\\'s columns while retaining {energy_threshold*100}% of the information')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3.1: Visualizing the path of the ﬁrst two pedestrians in the two-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_first_two_pedestrian_trajectories(file_path):\n",
    "    # Initialize lists to hold the coordinates for the first two pedestrians\n",
    "    x1, y1, x2, y2 = [], [], [], []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line by space and convert each part to float\n",
    "            coords = list(map(float, line.split()))\n",
    "            # Append the coordinates of the first pedestrian to x1 and y1\n",
    "            x1.append(coords[0])\n",
    "            y1.append(coords[1])\n",
    "            # Append the coordinates of the second pedestrian to x2 and y2\n",
    "            x2.append(coords[2])\n",
    "            y2.append(coords[3])\n",
    "\n",
    "            # print(f\"Pedestrian 1: x = {coords[0]}, y = {coords[1]}\")\n",
    "            # print(f\"Pedestrian 2: x = {coords[2]}, y = {coords[3]}\")\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "x1, y1, x2, y2 = load_first_two_pedestrian_trajectories('data_DMAP_PCA_vadere.txt')\n",
    "\n",
    "\n",
    "def avg_over_next_n_points(x, y, t, n):\n",
    "    xs = np.mean(np.array([x[t+i]-x[t] for i in range(1,n+1)], dtype=float))\n",
    "    ys = np.mean(np.array([y[t+i]-y[t] for i in range(1,n+1)], dtype=float))\n",
    "    norm = np.sqrt(xs**2 + ys**2)\n",
    "    return xs/norm, ys/norm\n",
    "\n",
    "def plot_trajectory_vectors(x, y, d, num_avg_points = 40, start_color='darkgreen', end_color='r', arrow_scale=10) -> None:\n",
    "    for i in range(0, 1000-num_avg_points, d):\n",
    "        my_color = end_color\n",
    "        if i == 0: my_color = start_color\n",
    "        \n",
    "        avg = avg_over_next_n_points(x, y, i, num_avg_points)\n",
    "        plt.quiver(x[i], y[i], avg[0], avg[1],scale=arrow_scale, color=my_color,zorder=2)\n",
    "\n",
    "\n",
    "# Plotting the paths for the first two pedestrians\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x1, y1, label='Pedestrian 1', marker='o')\n",
    "plt.scatter(x2, y2, label='Pedestrian 2', marker='o', color='orange')\n",
    "\n",
    "# Plot trajectory vectors\n",
    "plot_trajectory_vectors(x1, y1, 75, 30)\n",
    "\n",
    "plt.title('Paths of the First Two Pedestrians Over 1000 Timesteps')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- Each trajectory starts and ends at the starting point\n",
    "- The pedestrians appear to be walking in circles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3.1: Visualizing the path of the ﬁrst two pedestrians in the two-dimensional space: Gradient Coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_first_two_pedestrian_trajectories(file_path):\n",
    "    # Initialize lists to hold the coordinates for the first two pedestrians\n",
    "    x1, y1, x2, y2 = [], [], [], []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line by space and convert each part to float\n",
    "            coords = list(map(float, line.split()))\n",
    "            # Append the coordinates of the first pedestrian to x1 and y1\n",
    "            x1.append(coords[0])\n",
    "            y1.append(coords[1])\n",
    "            # Append the coordinates of the second pedestrian to x2 and y2\n",
    "            x2.append(coords[2])\n",
    "            y2.append(coords[3])\n",
    "\n",
    "            # print(f\"Pedestrian 1: x = {coords[0]}, y = {coords[1]}\")\n",
    "            # print(f\"Pedestrian 2: x = {coords[2]}, y = {coords[3]}\")\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "x1, y1, x2, y2 = load_first_two_pedestrian_trajectories('data_DMAP_PCA_vadere.txt')\n",
    "\n",
    "# Plotting the paths for the first two pedestrians\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create a time array from 0 to the number of points for pedestrian 1\n",
    "t1 = list(range(len(x1)))\n",
    "# Create a scatter plot for pedestrian 1, with the color representing time\n",
    "plt.scatter(x1, y1, c=t1, label='Pedestrian 1', cmap='Blues')\n",
    "plt.colorbar(label='Timestep for Pedestrian 1')\n",
    "\n",
    "# Create a time array from 0 to the number of points for pedestrian 2\n",
    "t2 = list(range(len(x2)))\n",
    "# Create a scatter plot for pedestrian 2, with the color representing time\n",
    "plt.scatter(x2, y2, c=t2, label='Pedestrian 2', cmap='Greens')\n",
    "plt.colorbar(label='Timestep for Pedestrian 2')\n",
    "plt.title('Paths of the First Two Pedestrians Over 1000 Timesteps')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Part: Vadere pedestrian trajectory data\n",
    "\n",
    "We load the data from the file and perform PCA on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_DMAP_PCA_vadere.txt\", 'r') as file:\n",
    "    # Load data inta a Python ndarray, shape (100, 2)\n",
    "    global trajectory_matrix\n",
    "    trajectory_matrix = np.loadtxt(file, delimiter=' ')\n",
    "    print(f'Trajectory matrix shape: {trajectory_matrix.shape}')\n",
    "    assert trajectory_matrix.shape == (1000, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data represents 15 pedestrians with coordinates (x, y). The columns are the timesteps\n",
    "\n",
    "We visualize the points for a given timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(timestep):\n",
    "    # timesteps are rows\n",
    "    trajectory = trajectory_matrix[timestep]\n",
    "    x = trajectory[::2]\n",
    "    y = trajectory[1::2]\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(f'Timestep: {timestep}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()\n",
    "    \n",
    "# plot_trajectory(0)\n",
    "\n",
    "# Plot trajectories over time:\n",
    "\n",
    "for i in range(0, 1000, 100):\n",
    "    plot_trajectory(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
